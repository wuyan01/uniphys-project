<!DOCTYPE html>
<html>
<head>

  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-K6ZT9FLT77"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-K6ZT9FLT77');
  </script>

  <meta charset="utf-8">
  <meta name="description"
        content="DNO: Optimizing Diffusion Noise Can Serve As Universal Motion Priors">
  <meta name="keywords" content="DNO, diffusion noise optimization, diffusion latent space, human motion, motion synthesis">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>DNO: Optimizing Diffusion Noise Can Serve As Universal Motion Priors</title>


  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="shortcut icon" href="images.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<!-- <nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>
    </div>

  </div>
</nav> -->


<section class="publication-header">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">UniPhys: Unified Planner and Controller with Diffusion for Flexible Physics-Based Character Control</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://wuyan01.github.io/">Yan Wu</a><sup>1</sup>,</span> 
            <span class="author-block">
              <a href="https://korrawe.github.io/">Korrawe Karunratanakul</a><sup>1</sup>,</span> 
            <span class="author-block">
              <a href="https://www.zhengyiluo.com/">Zhengyi Luo</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://vlg.inf.ethz.ch/team/Prof-Dr-Siyu-Tang.html">Siyu Tang</a><sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>ETH Zurich </span> &nbsp &nbsp
            <span class="author-block"><sup>2</sup>Carnegie Mellon University </span>  <br>
            <!-- <span class="author-block"><sup>1</sup>ETH Zurich</span> -->
          </div>

          <!-- <h3 class="is-5 conference">ICCV 2023</h3> -->

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <!-- <span class="link-block">
                <a href="https://arxiv.org/abs/2212."
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span> -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. --> 
              <span class="link-block">
                <a href="https://youtu.be/n9anQM4h-FE" 
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Dataset Link. --> 
              <span class="link-block">
                <a href="" 
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fas fa-database"></i>
                  </span>
                  <span>Dataset (Coming)</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code (Coming)</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <!-- <span class="link-block">
                <a href="https://github.com/1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a> -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <!-- <div class="hero-body">
      <img src="./static/images/teaser.png"
                 class="column is-centered has-text-centered"
                 alt="Teaser image."/> -->

      <!-- <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/video_v1.mp4"
                type="video/mp4">
      </video> -->

      <!-- <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column">
            <div class="content">
              <video id="video1" autoplay controls muted loop width="448">
                <source src="./static/videos/Responsive_text_driven_control_long.mp4" type="video/mp4">
              </video>
              <p class="has-text-centered">(a) Interactive text-driven control</p>
            </div>
          </div>
          <div class="column">
            <div class="content">
              <video id="video2" autoplay controls muted loop width="448">
                <source src="./static/videos/baseline_comparison/Ours/velocity_control/ours_vel_control.mp4" type="video/mp4">
              </video>
              <p class="has-text-centered">(b) Velocity control</p>
            </div>
          </div>
        </div> -->
        
        <!-- <div class="columns is-centered">
          <div class="column">
            <div class="content">
              <video id="video3" autoplay controls muted loop width="448">
                <source src="./static/videos/baseline_comparison/Ours/goal_reaching/ours_long_walk.mp4" type="video/mp4">
              </video>
              <p class="has-text-centered">(c) Sparse goal reaching</p>
            </div>
          </div>
          <div class="column">
            <div class="content">
              <video id="video4" autoplay controls muted loop width="448">
                <source src="./static/videos/baseline_comparison/Ours/object_avoid/Object_avoidance_results.mp4" type="video/mp4">
              </video>
              <p class="has-text-centered">(d) Dynamic object avoidance</p>
            </div>
          </div>
        </div> -->
      <!-- </div> -->


      <!-- Paper video. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <!-- <h2 class="title is-3">Video</h2> -->
          <div class="publication-video">
            <iframe src="https://www.youtube.com/embed/n9anQM4h-FE?si=ew_1NKYxR5QnKtCY"
                    frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
      <!--/ Paper video. -->

      <br>
      <br>

      <h2 class="subtitle has-text-centered">
        <b> UniPhys </b> is a diffusion-based unified planner and text-driven controller for physics-based character control.
        It generalizes across diverse tasks using a single modelâ€”from short-term reactive control tasks to long-term planning tasks, without requiring task-specific training.
      </h2>
    </div>
</section>

<br>
<br>

<!-- <section class="section"> -->
<section class="hero is-light is-small">
  <div class="container is-max-desktop">
    <br>
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Generating natural and physically plausible character motion remains challenging, particularly for long-horizon control with diverse guidance signals. 
            While prior work combines high-level diffusion-based motion planners with low-level physics controllers, these systems suffer from domain gaps that degrade motion quality and require task-specific fine-tuning.
            To tackle this problem, we introduce UniPhys, a diffusion-based behavior cloning framework that unifies motion planning and control into a single model. UniPhys enables flexible, expressive character motion conditioned on multi-modal inputs such as text, trajectories, and goals. To address accumulated prediction errors over long sequences, UniPhys is trained with the Diffusion Forcing paradigm, learning to denoise noisy motion histories and handle discrepancies introduced by the physics simulator. This design allows UniPhys to robustly generate physically plausible, long-horizon motions. 
            Through guided sampling, UniPhys generalizes to a wide range of control signals, including unseen ones, without requiring task-specific fine-tuning. 
            Experiments show that UniPhys outperforms prior methods in motion naturalness, generalization, and robustness across diverse control tasks.
          </p>
          <!-- <p>
            We propose Diffusion Noise Optimization (DNO), a new method that effectively leverages existing motion diffusion models as motion priors for a wide range of motion-related tasks.
          </p>
          <p>
            Instead of training a task-specific diffusion model for each new task, DNO operates by optimizing the diffusion latent noise of an existing pre-trained text-to-motion model.
            Given the corresponding latent noise of a human motion, it propagates the gradient from the target criteria defined on the motion space through the whole denoising process to update the diffusion latent noise. As a result, DNO supports any use cases where criteria can be defined as a function of motion. 
          </p>
          <p>
            In particular, we show that, for motion editing and control, DNO outperforms existing methods in both achieving the objective and preserving the motion content. 
            DNO accommodates a diverse range of editing modes, including changing trajectory, pose, joint locations, or avoiding newly added obstacles.
          </p>
          <p>
            In addition, DNO is effective in motion denoising and completion, producing smooth and realistic motion from noisy and partial inputs.
            DNO achieves these results at inference time without the need for model retraining, offering great versatility for any defined reward or loss function on the motion representation.
          </p> -->
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <!-- <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/heWXQdIjSzs?si=QDc62aFZW8uLj-e3"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div> -->
    <!--/ Paper video. -->
  </div>
  <br/>
</section>
<!-- <iframe width="560" height="315" src="https://www.youtube.com/embed/heWXQdIjSzs?si=QDc62aFZW8uLj-e3" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe> -->


<section class="section">
  <div class="container is-max-desktop">
    <!-- Summary -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Method</h2>
        <div class="content has-text-justified">
          <h4>Key Idea</h4>
          We're building a diffusion-based model that learns <b>both kinematic motion and physical control actions</b>, acting as a unified planner and a text-driven controller.
          <br>
          By directly modeling the text-conditioned action distribution, we can control a character <b>end-to-end</b> with text instructions. 
          <br>
          Plus, since weâ€™re learning the full state-action distribution, we can predict future motions and apply flexible guidance during denoising to steer actions toward a desired goal.
          <br>
          This approach works for <b>any task</b> as long as we can design a differentiable guidance loss over the state-action space.
          
          <!-- <figure  class="content has-text-centered">
            <img src="./static/images/guidance_problem.jpg"
                   class="column is-7 is-offset-1 has-text-centered"
                   alt="Guidance problem."
                   />
          </figure > -->
          <p>
          <h4>Key Challenges</h4>
          <p>
            However, simply training the diffusion model with offline paired state-action data doesnâ€™t work wellâ€”it often leads to unstable motions, with the character frequently falling.
            <br>
            <br>
            What makes this challenging?
            <br>
            <br>
            <span style="color: #ff0000"><b>Difficult bipedal control</b></span> â€“ Controlling a full-body character is tough. The action space is large (69 dimensions, excluding fingers control), and even small errors can throw off balance, causing falls.
            <br>
            <br>
            <span style="color: #ff0000"><b>Compounding error in behavior cloning</b></span> â€“ Training on offline data suffers from the classic compounding error problem. As the state drifts beyond the training distribution over time, predictions become less accurate, leading to unstable and unreliable control.

          </p>

          <h4>Our Solutions</h4>
          <p>
            <span style="color: #0bbe05"><b>Latent action representation</b></span> â€“ Instead of directly learning the high-dimensional action distribution, we employ a compact latent action representation for ease of learning.
            <br>
            <br>
            <span style="color: #0bbe05"><b>Injecting independant noises per frame when training</b></span> â€“ Inspired by Diffusion Forcing, when predicting clean output from corrupted noisy input at training time, we corrupt the input sequence by injecting independant noises to each frame.
            <br>
            This enables flexible denoising settings and a stabilization trick to mitigate compounding error issues at inference time:
            <br>
            <ul>
              <li><b>Flexible denoising settings</b> â€“ As the model has seen various random noise configurations at training time, we can adjust noise levels at inference time. 
                This allows for more flexible denoising schedules for the sequence beyond the standard uniform denoising schedule over a fixed-length sequence.
                We can design custom denoising schedules and even use different lengths of past motion to predict variable-length future motions, by simpling setting different noise levels.</li>
              <li><b>Stabilization method</b> â€“ When generating future motions autoregressively, predictions are conditioned on previously predicted frames. 
                However, these frames may slightly deviate from the training distribution. 
                To prevent the model from treating them as perfect ground truth, we introduce a small amount of noise to indicate potential uncertainty. 
                This helps mitigate compounding errors in long-horizon rollouts, leading to more stable motion generation.</li>
            </ul>
            <br>
          </p>
             
          <figure  class="content has-text-centered">
            <img src="./static/images/UniPhys-Framework.png"
                   
                   class="is-fullwidth"
                   alt="Method Overview."
                   />
          </figure >
          </p>
        </div>
        
      </div>
    </div>

    <!-- Pipeline
    <div class="columns is-centered has-text-centered">
      
    </div> -->
    
    <!-- <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Hand Avatar</h2>

        <h3 class="title is-4">Robustness</h3>
        <div class="content has-text-justified">
          <p>
            Given a short video, HARP can create an avatar from different capturing scenarios.
          </p>
        </div>
        <div class="content has-text-centered">
          <img src="./static/images/other_dataset.jpg"
                 class="column is-centered has-text-centered"
                 alt="results in different dataset."/>
        </div>
        <br/>

        <h3 class="title is-4">Out-of-distribution appearance</h3>
        <div class="content has-text-justified">
          <p>
            HARP works without modification for out-of-distribution appearance that cannot be captured by parametric models.
          </p>
        </div>
        <div class="content has-text-centered">
          <img src="./static/images/tattoo_single.jpg"
                 class="column is-centered has-text-centered"
                 alt="Out-of-distribution result."/>
        </div>


      </div>
    </div> -->



  </div>
</section>


<section class="hero is-light is-small">
  <div class="hero-body">
    <br>
    <div class="columns is-centered has-text-centered">
      <h2 class="title is-2">Results</h2>
      <br>
    </div>
    

    <!-- <hr /> -->
    <!-- <div class="content has-text-justified">
    <h4>
        <ol>
          <li><a href="#random_long_rollout" class="has-text-underlined">Random Motion Generation</a></li>
            <li><a href="#application">Application</a></li>
            <ul>
                <li><a href="#application_t2m">Text-driven Policy</a></li>
                <ul>
                  <li><a href="#application_t2m_response">Interactive text-driven controller</a></li>
                  <li><a href="#application_multi_modal">Multi-modal text-driven controller</a></li>
                </ul>
                <li><a href="#application_velocity_control">Velocity Control</a></li>
                <li><a href="#application_goal_reach">Goal Reaching</a></li>
                <li><a href="#application_obj_avoid">Dynamic Object Avoidance</a></li>
            </ul>
            
            <li><a href="#baselines">Compare with baselines</a></li>
            <ul>
              <li><a href="#compare_t2m">Baseline comparison: Text-driven control</a></li>
              <li><a href="#compare_velocity_control">Baseline comparison: Velocity Control</a></li>
              <li><a href="#compare_goal_reaching">Baseline comparison: Goal Reaching</a></li>
          </ul>
      </ol>
    </h4>
  </div>  -->
    <!-- <hr /> -->
    
    <div class="columns is-centered has-text-centered">
      <h2 class="title is-3" id = "random_long_rollout" style="color:#f0a00c">
        Long-horizon random rollouts
      </h2>
    </div>
    

    <!-- <h2 style="text-align: center;" id = "random_long_rollout">Long-horizon unconditional random rollouts</h2> -->
    <div class="content has-text-justified">
      <p class="subtitle has-text-centered is-offset-4">
        UniPhys produces stable long-horizon rollouts, covering diverse skills.
      </p>
    </div>
      
      <table
      style="
        width: 60%;
        border: 0px;
        border-spacing: 5px 0px;
        border-collapse: separate;
        margin-right: auto;
        margin-left: auto;
        padding-bottom: 20px;
      "
    >

      <tbody>
          <tr class="block_videos">
              <td>
              <video width="100%" height="auto" muted autoplay loop controls>
                  <source
                  src="static/videos/Unconditional_long_rollouts.mp4"
                  type="video/mp4 "
                  />
                  Your browser does not support the video tag.
              </video>
              </td>
          </tr>

    </tbody>
    </table>
    
    <!-- </div> -->
    
    <div class="column is-centered has-text-centered">
      <h2 class="title is-3" style="color:#f0a00c">
        Text-driven control
      </h2>
    </div>

    <!-- <br> -->

    <div class="content is-centered has-text-centered">
      <h2 class="title is-4">
        Multi-modal text-driven atomic skills
      </h2>
    </div>

    <!-- carousel -->
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item 100">
          <video poster="" id="pelvis3" autoplay controls muted loop height="100%">
            <source src="./static/videos/multi-samples/multi-jog_forward.mp4"
                    type="video/mp4">
        </video>
        </div>
        <div class="item 4602">
          <video poster="" id="pelvis" autoplay controls muted loop height="100%">
            <source src="./static/videos/multi-samples/multi-jump_up.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item 559">
          <video poster="" id="pelvis1" autoplay controls muted loop height="100%">
            <source src="./static/videos/multi-samples/multi-kick_left_leg.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item 277">
          <video poster="" id="pelvis2" autoplay controls muted loop height="100%">
            <source src="./static/videos/multi-samples/multi-raise_both_arms_up.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item 100">
          <video poster="" id="pelvis3" autoplay controls muted loop height="100%">
            <source src="./static/videos/multi-samples/multi-squat.mp4"
                    type="video/mp4">
        </video>
        </div>
        <div class="item 100">
          <video poster="" id="pelvis3" autoplay controls muted loop height="100%">
            <source src="./static/videos/multi-samples/multi-sidestep.mp4"
                    type="video/mp4">
        </video>
        </div>
        <div class="item 100">
          <video poster="" id="pelvis3" autoplay controls muted loop height="100%">
            <source src="./static/videos/multi-samples/multi-step_backward.mp4"
                    type="video/mp4">
        </video>
        </div>
        <div class="item 100">
          <video poster="" id="pelvis3" autoplay controls muted loop height="100%">
            <source src="./static/videos/multi-samples/multi-walk_in_circle.mp4"
                    type="video/mp4">
        </video>
        </div>
      </div>
    </div>

    <br>
    <br>


    <div class="content is-centered has-text-centered">
      <h2 class="title is-4">
        Interactive text-driven control
      </h2>
    </div>

    <table
      style="
        width: 60%;
        border: 0px;
        border-spacing: 5px 0px;
        border-collapse: separate;
        margin-right: auto;
        margin-left: auto;
        padding-bottom: 20px;
      "
    >

      <tbody>
          <tr class="block_videos">
              <td>
              <video width="100%" height="auto" muted autoplay loop controls>
                  <source
                  src="static/videos/Responsive_1.mp4"
                  type="video/mp4 "
                  />
                  Your browser does not support the video tag.
              </video>
              </td>

              <td style="width: 50%; text-align: center;">
                <video width="100%" height="auto" muted autoplay loop controls>
                  <source
                    src="static/videos/Responsive_2.mp4"
                    type="video/mp4 "
                  />
                  Your browser does not support the video tag.
                </video>
              </td>
          </tr>

    </tbody>
    </table>
    
    <div class="column is-centered has-text-centered">
      <h2 class="title is-3" style="color:#f0a00c">
        Goal reaching
      </h2>
    </div>
      
      <table
      style="
        width: 60%;
        border: 0px;
        border-spacing: 5px 0px;
        border-collapse: separate;
        margin-right: auto;
        margin-left: auto;
        padding-bottom: 20px;
      "
    >

      <tbody>
          <tr class="block_videos">
              <td>
              <video width="100%" height="auto" muted autoplay loop controls>
                  <source
                  src="static/videos/baseline_comparison/Ours/goal_reaching/ours_long_walk.mp4"
                  type="video/mp4 "
                  />
                  Your browser does not support the video tag.
              </video>
              </td>
          </tr>
    </tbody>
    </table>

    <div class="column is-centered has-text-centered">
      <h2 class="title is-3" style="color:#f0a00c">
        Velocity control
      </h2>
    </div>
      
      <table
      style="
        width: 60%;
        border: 0px;
        border-spacing: 5px 0px;
        border-collapse: separate;
        margin-right: auto;
        margin-left: auto;
        padding-bottom: 20px;
      "
    >

      <tbody>
          <tr class="block_videos">
              <td>
              <video width="100%" height="auto" muted autoplay loop controls>
                  <source
                  src="static/videos/baseline_comparison/Ours/velocity_control/ours_vel_control.mp4"
                  type="video/mp4 "
                  />
                  Your browser does not support the video tag.
              </video>
              </td>
          </tr>
    </tbody>
    </table>

    <div class="column is-centered has-text-centered">
      <h2 class="title is-3" style="color:#f0a00c">
        Dynamic object avoidance
      </h2>
    </div>
      
      <table
      style="
        width: 60%;
        border: 0px;
        border-spacing: 5px 0px;
        border-collapse: separate;
        margin-right: auto;
        margin-left: auto;
        padding-bottom: 20px;
      "
    >

      <tbody>
          <tr class="block_videos">
              <td>
              <video width="100%" height="auto" muted autoplay loop controls>
                  <source
                  src="static/videos/baseline_comparison/Ours/object_avoid/Object_avoidance_results.mp4"
                  type="video/mp4 "
                  />
                  Your browser does not support the video tag.
              </video>
              </td>
          </tr>
    </tbody>
    </table>




    </div>
  </div>
  <br>
</section>


<!-- <section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@inproceedings{karunratanakul2023dno,
  title={Optimizing Diffusion Noise Can Serve As Universal Motion Priors},
  author={Karunratanakul, Korrawe and Preechakul, Konpat and Aksan, Emre and Beeler, Thabo and Suwajanakorn, Supasorn and Tang, Siyu},
  booktitle={arxiv:2312.11994},
  year={2023}
}</code></pre>
  </div>
</section> -->


<footer class="footer">
  <div class="container">
    <!-- <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div> -->
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            We use the website template provided by <a
              href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
